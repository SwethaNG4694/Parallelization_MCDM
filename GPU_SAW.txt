import math
from numba import cuda, float32
import numpy
import time

@cuda.jit
def min_max_calculation(qos,min_max,qos_rows,qos_col):
  col = cuda.grid(1)
  if col < qos_col:
    if col==0:
      temp=99999
      for i in range(0,qos_rows):
        if qos[i][col]<temp:
          temp=qos[i][col]
      min_max[col]=temp
    else:
      temp1=0
      for i in range(0,qos_rows):
        if qos[i][col]>temp1:
          temp1=qos[i][col]
      min_max[col]=temp1

@cuda.jit
def normalization_cal(qos,min_max,NM,qos_rows,qos_col):
  row, col = cuda.grid(2)
  if row < qos_rows and col < qos_col:
    if col==0:
        NM[row][col]=min_max[col]/qos[row][col]
    else:
        NM[row][col]=qos[row][col]/min_max[col]

@cuda.jit
def weighted_normalization_cal(weight,NM,NDM,qos_rows,qos_col):
  row, col = cuda.grid(2)
  if row < qos_rows and col < qos_col:
    NDM[row][col]=weight[col]*NM[row][col]

@cuda.jit
def performance_score_cal(NDM,P1,qos_rows,qos_col):
  row = cuda.grid(1)
  if row < qos_rows :
    for i in range(0,qos_col):
      P1[row]+=NDM[row][i]



qos= [[250,16,12,5],[200,16,8,3],[300,32,16,4],[275,32,8,4],[225,16,16,2]]
qos_rows=len(qos)
qos_col=4
NM=[[0.0 for i in range(qos_col)] for j in range(qos_rows)] 
min_max=[0.0 for i in range(qos_col)]
weight=[0.25,0.25,0.25,0.25]
NDM=[[0.0 for i in range(qos_col)] for j in range(qos_rows)] 
p1=[0.0 for i in range(qos_rows)]
service=[]
for i in range(0,qos_rows):
    service.append(i+1)

#copy to global memory
qos_global_mem = cuda.to_device(qos)
NM_global_mem = cuda.to_device(NM)
min_max_global_mem = cuda.to_device(min_max)
weight_global_mem = cuda.to_device(weight)
NDM_global_mem = cuda.to_device(NDM)
P1_global_mem = cuda.to_device(p1)

# Configure the blocks min_max_normalization
threadsperblock = qos_col
blockspergrid = math.ceil(qos_col / threadsperblock)

start_time =time.time() 

min_max_calculation[blockspergrid, threadsperblock](qos_global_mem,min_max_global_mem,qos_rows,qos_col)
min_max = min_max_global_mem.copy_to_host()

#configure the blocks for Normalized Matrix
threadsperblock = (250, qos_col)
blockspergrid_x = int(math.ceil(qos_rows / threadsperblock[0]))
blockspergrid_y = int(math.ceil(qos_col / threadsperblock[1]))
blockspergrid = (blockspergrid_x, blockspergrid_y)

normalization_cal[blockspergrid, threadsperblock](qos_global_mem,min_max_global_mem,NM_global_mem,qos_rows,qos_col)
NM = NM_global_mem.copy_to_host()

#Weighted Normalized Matrix

weighted_normalization_cal[blockspergrid, threadsperblock](weight_global_mem,NM_global_mem,NDM_global_mem ,qos_rows,qos_col)
NDM = NDM_global_mem.copy_to_host()

#Performance Score
threadsperblock = 250
blockspergrid = math.ceil(250 / threadsperblock)

performance_score_cal[blockspergrid, threadsperblock](NDM_global_mem,P1_global_mem,qos_rows,qos_col)
p1 = P1_global_mem.copy_to_host()

array = numpy.array(p1)
order = array.argsort()
ranks = order.argsort()
l1=list(ranks)
l2=list(service)
l1,l2=zip(*sorted(zip(l1, l2)))
new_tup = l2[::-1] 
duration = time.time() - start_time
print("---------------------------------------------------")
print("P- SAW GPU - Number of Services:",qos_rows)
print("---------------------------------------------------")
print("Ranking based on P-TOPSIS !!!")
#print(new_tup)
print("---------------------------------------------------")
print("Total time for Execution !!!")
print(duration)
